# ğŸ§  Neural Network From Scratch in NumPy

This project implements a fully-functional neural network from scratch using only **NumPy**â€”no external ML frameworks like TensorFlow or PyTorch.

It classifies **handwritten digit images** (0â€“9) and was trained on a custom dataset. The network uses a two-layer architecture with:
- Hidden Layer: 64 neurons (Sigmoid activation)
- Output Layer: 10 neurons (Softmax activation)

---

## ğŸ“Œ Features

- ğŸ§® Custom-built forward and backward propagation
- ğŸ§  Manual implementation of softmax and cross-entropy loss
- ğŸ§¾ One-hot encoding of labels
- ğŸ‹ï¸ Gradient descent training loop
- ğŸ’¾ Model persistence using `.npy` files which were obtained from training the model.
- ğŸ§ª Interactive prediction with new digit images
- ğŸ“Š Live training loss visualization with Matplotlib

---

##
